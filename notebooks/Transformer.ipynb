{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a69bed1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T17:00:52.901261Z",
     "start_time": "2021-07-27T17:00:52.896481Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from torchvision import transforms, datasets\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensor\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e43b498a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T19:41:30.508113Z",
     "start_time": "2021-07-27T19:41:29.725709Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "batch_size = 32\n",
    "data_folder = \"~/datasets/CIFAR10\"\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_folder, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=data_folder, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = trainset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59944b59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T19:31:50.768033Z",
     "start_time": "2021-07-27T19:31:50.633560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck   dog horse truck   cat  ship   cat  ship\n"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:8]))\n",
    "# print labels\n",
    "print(' '.join('%5s' % trainset.classes[labels[j]] for j in range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "738f19df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T22:17:05.118209Z",
     "start_time": "2021-07-27T22:17:05.054625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 512, kernel_size=(8, 8), stride=(8, 8))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.1, inplace=False)\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net = nn.Sequential(\n",
    "#     nn.LazyConv2d(64, 5),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2, 2),\n",
    "#     nn.LazyConv2d(128, 3),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2, 2),\n",
    "#     nn.LazyConv2d(256, 3),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2, 2),\n",
    "#     Rearrange(\"b c h w -> b (c h w)\"),\n",
    "#     nn.LazyLinear(1024),\n",
    "#     nn.ReLU(),\n",
    "#     nn.LazyLinear(256),\n",
    "#     nn.ReLU(),\n",
    "#     nn.LazyLinear(10),\n",
    "# )\n",
    "\n",
    "class TorchTransformer(nn.Module):\n",
    "    def __init__(self, img_size=32, patch_size=8, embed_dim=512, \n",
    "                 num_heads=8, num_layers=6, num_classes=10, \n",
    "                 drop_rate=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.patch_embed = PatchEmbed(img_size, patch_size, embed_dim=embed_dim)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        \n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(embed_dim, num_heads, dropout=drop_rate, \n",
    "                                                   activation='gelu', batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.norm = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_token, x), dim=1)\n",
    "        x = self.pos_drop(x + self.pos_embed)\n",
    "        x = self.transformer(x)\n",
    "        x = self.norm(x)\n",
    "        # maybe insert norm here\n",
    "        x = self.classifier(x[:, 0])\n",
    "        return x\n",
    "\n",
    "net = TorchTransformer()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "698ca0d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T22:17:11.905389Z",
     "start_time": "2021-07-27T22:17:11.901648Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "39e483e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T22:34:06.883496Z",
     "start_time": "2021-07-27T22:17:15.694690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.206\n",
      "[1,   400] loss: 0.194\n",
      "[1,   600] loss: 0.190\n",
      "[1,   800] loss: 0.183\n",
      "[1,  1000] loss: 0.181\n",
      "[1,  1200] loss: 0.177\n",
      "[1,  1400] loss: 0.176\n",
      "Epoch 0\t Accuracy of the network on the 10000 test images: 37 %\n",
      "[2,   200] loss: 0.168\n",
      "[2,   400] loss: 0.169\n",
      "[2,   600] loss: 0.165\n",
      "[2,   800] loss: 0.164\n",
      "[2,  1000] loss: 0.164\n",
      "[2,  1200] loss: 0.163\n",
      "[2,  1400] loss: 0.159\n",
      "Epoch 1\t Accuracy of the network on the 10000 test images: 42 %\n",
      "[3,   200] loss: 0.154\n",
      "[3,   400] loss: 0.154\n",
      "[3,   600] loss: 0.154\n",
      "[3,   800] loss: 0.151\n",
      "[3,  1000] loss: 0.151\n",
      "[3,  1200] loss: 0.149\n",
      "[3,  1400] loss: 0.148\n",
      "Epoch 2\t Accuracy of the network on the 10000 test images: 46 %\n",
      "[4,   200] loss: 0.141\n",
      "[4,   400] loss: 0.143\n",
      "[4,   600] loss: 0.142\n",
      "[4,   800] loss: 0.139\n",
      "[4,  1000] loss: 0.140\n",
      "[4,  1200] loss: 0.140\n",
      "[4,  1400] loss: 0.138\n",
      "Epoch 3\t Accuracy of the network on the 10000 test images: 47 %\n",
      "[5,   200] loss: 0.134\n",
      "[5,   400] loss: 0.133\n",
      "[5,   600] loss: 0.134\n",
      "[5,   800] loss: 0.134\n",
      "[5,  1000] loss: 0.135\n",
      "[5,  1200] loss: 0.132\n",
      "[5,  1400] loss: 0.131\n",
      "Epoch 4\t Accuracy of the network on the 10000 test images: 50 %\n",
      "[6,   200] loss: 0.128\n",
      "[6,   400] loss: 0.129\n",
      "[6,   600] loss: 0.126\n",
      "[6,   800] loss: 0.127\n",
      "[6,  1000] loss: 0.125\n",
      "[6,  1200] loss: 0.126\n",
      "[6,  1400] loss: 0.126\n",
      "Epoch 5\t Accuracy of the network on the 10000 test images: 51 %\n",
      "[7,   200] loss: 0.120\n",
      "[7,   400] loss: 0.119\n",
      "[7,   600] loss: 0.118\n",
      "[7,   800] loss: 0.123\n",
      "[7,  1000] loss: 0.119\n",
      "[7,  1200] loss: 0.121\n",
      "[7,  1400] loss: 0.121\n",
      "Epoch 6\t Accuracy of the network on the 10000 test images: 54 %\n",
      "[8,   200] loss: 0.115\n",
      "[8,   400] loss: 0.115\n",
      "[8,   600] loss: 0.114\n",
      "[8,   800] loss: 0.116\n",
      "[8,  1000] loss: 0.116\n",
      "[8,  1200] loss: 0.113\n",
      "[8,  1400] loss: 0.114\n",
      "Epoch 7\t Accuracy of the network on the 10000 test images: 55 %\n",
      "[9,   200] loss: 0.108\n",
      "[9,   400] loss: 0.108\n",
      "[9,   600] loss: 0.109\n",
      "[9,   800] loss: 0.111\n",
      "[9,  1000] loss: 0.109\n",
      "[9,  1200] loss: 0.110\n",
      "[9,  1400] loss: 0.110\n",
      "Epoch 8\t Accuracy of the network on the 10000 test images: 56 %\n",
      "[10,   200] loss: 0.103\n",
      "[10,   400] loss: 0.106\n",
      "[10,   600] loss: 0.107\n",
      "[10,   800] loss: 0.105\n",
      "[10,  1000] loss: 0.105\n",
      "[10,  1200] loss: 0.105\n",
      "[10,  1400] loss: 0.103\n",
      "Epoch 9\t Accuracy of the network on the 10000 test images: 56 %\n",
      "[11,   200] loss: 0.097\n",
      "[11,   400] loss: 0.101\n",
      "[11,   600] loss: 0.100\n",
      "[11,   800] loss: 0.099\n",
      "[11,  1000] loss: 0.099\n",
      "[11,  1200] loss: 0.101\n",
      "[11,  1400] loss: 0.101\n",
      "Epoch 10\t Accuracy of the network on the 10000 test images: 58 %\n",
      "[12,   200] loss: 0.093\n",
      "[12,   400] loss: 0.094\n",
      "[12,   600] loss: 0.095\n",
      "[12,   800] loss: 0.094\n",
      "[12,  1000] loss: 0.098\n",
      "[12,  1200] loss: 0.094\n",
      "[12,  1400] loss: 0.097\n",
      "Epoch 11\t Accuracy of the network on the 10000 test images: 58 %\n",
      "[13,   200] loss: 0.091\n",
      "[13,   400] loss: 0.089\n",
      "[13,   600] loss: 0.091\n",
      "[13,   800] loss: 0.091\n",
      "[13,  1000] loss: 0.093\n",
      "[13,  1200] loss: 0.091\n",
      "[13,  1400] loss: 0.089\n",
      "Epoch 12\t Accuracy of the network on the 10000 test images: 59 %\n",
      "[14,   200] loss: 0.083\n",
      "[14,   400] loss: 0.086\n",
      "[14,   600] loss: 0.088\n",
      "[14,   800] loss: 0.084\n",
      "[14,  1000] loss: 0.087\n",
      "[14,  1200] loss: 0.087\n",
      "[14,  1400] loss: 0.088\n",
      "Epoch 13\t Accuracy of the network on the 10000 test images: 59 %\n",
      "[15,   200] loss: 0.080\n",
      "[15,   400] loss: 0.080\n",
      "[15,   600] loss: 0.082\n",
      "[15,   800] loss: 0.082\n",
      "[15,  1000] loss: 0.085\n",
      "[15,  1200] loss: 0.079\n",
      "[15,  1400] loss: 0.084\n",
      "Epoch 14\t Accuracy of the network on the 10000 test images: 59 %\n",
      "[16,   200] loss: 0.078\n",
      "[16,   400] loss: 0.078\n",
      "[16,   600] loss: 0.077\n",
      "[16,   800] loss: 0.078\n",
      "[16,  1000] loss: 0.079\n",
      "[16,  1200] loss: 0.078\n",
      "[16,  1400] loss: 0.079\n",
      "Epoch 15\t Accuracy of the network on the 10000 test images: 60 %\n",
      "[17,   200] loss: 0.073\n",
      "[17,   400] loss: 0.072\n",
      "[17,   600] loss: 0.074\n",
      "[17,   800] loss: 0.073\n",
      "[17,  1000] loss: 0.076\n",
      "[17,  1200] loss: 0.077\n",
      "[17,  1400] loss: 0.075\n",
      "Epoch 16\t Accuracy of the network on the 10000 test images: 60 %\n",
      "[18,   200] loss: 0.067\n",
      "[18,   400] loss: 0.066\n",
      "[18,   600] loss: 0.068\n",
      "[18,   800] loss: 0.070\n",
      "[18,  1000] loss: 0.069\n",
      "[18,  1200] loss: 0.070\n",
      "[18,  1400] loss: 0.073\n",
      "Epoch 17\t Accuracy of the network on the 10000 test images: 59 %\n",
      "[19,   200] loss: 0.063\n",
      "[19,   400] loss: 0.064\n",
      "[19,   600] loss: 0.064\n",
      "[19,   800] loss: 0.066\n",
      "[19,  1000] loss: 0.066\n",
      "[19,  1200] loss: 0.066\n",
      "[19,  1400] loss: 0.067\n",
      "Epoch 18\t Accuracy of the network on the 10000 test images: 60 %\n",
      "[20,   200] loss: 0.058\n",
      "[20,   400] loss: 0.058\n",
      "[20,   600] loss: 0.059\n",
      "[20,   800] loss: 0.060\n",
      "[20,  1000] loss: 0.062\n",
      "[20,  1200] loss: 0.064\n",
      "[20,  1400] loss: 0.064\n",
      "Epoch 19\t Accuracy of the network on the 10000 test images: 60 %\n",
      "[21,   200] loss: 0.055\n",
      "[21,   400] loss: 0.054\n",
      "[21,   600] loss: 0.057\n",
      "[21,   800] loss: 0.056\n",
      "[21,  1000] loss: 0.058\n",
      "[21,  1200] loss: 0.061\n",
      "[21,  1400] loss: 0.058\n",
      "Epoch 20\t Accuracy of the network on the 10000 test images: 60 %\n",
      "[22,   200] loss: 0.050\n",
      "[22,   400] loss: 0.051\n",
      "[22,   600] loss: 0.053\n",
      "[22,   800] loss: 0.052\n",
      "[22,  1000] loss: 0.056\n",
      "[22,  1200] loss: 0.054\n",
      "[22,  1400] loss: 0.054\n",
      "Epoch 21\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[23,   200] loss: 0.046\n",
      "[23,   400] loss: 0.047\n",
      "[23,   600] loss: 0.048\n",
      "[23,   800] loss: 0.047\n",
      "[23,  1000] loss: 0.051\n",
      "[23,  1200] loss: 0.050\n",
      "[23,  1400] loss: 0.052\n",
      "Epoch 22\t Accuracy of the network on the 10000 test images: 60 %\n",
      "[24,   200] loss: 0.040\n",
      "[24,   400] loss: 0.042\n",
      "[24,   600] loss: 0.045\n",
      "[24,   800] loss: 0.046\n",
      "[24,  1000] loss: 0.046\n",
      "[24,  1200] loss: 0.046\n",
      "[24,  1400] loss: 0.049\n",
      "Epoch 23\t Accuracy of the network on the 10000 test images: 59 %\n",
      "[25,   200] loss: 0.038\n",
      "[25,   400] loss: 0.038\n",
      "[25,   600] loss: 0.042\n",
      "[25,   800] loss: 0.039\n",
      "[25,  1000] loss: 0.045\n",
      "[25,  1200] loss: 0.044\n",
      "[25,  1400] loss: 0.044\n",
      "Epoch 24\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[26,   200] loss: 0.033\n",
      "[26,   400] loss: 0.034\n",
      "[26,   600] loss: 0.038\n",
      "[26,   800] loss: 0.039\n",
      "[26,  1000] loss: 0.039\n",
      "[26,  1200] loss: 0.040\n",
      "[26,  1400] loss: 0.038\n",
      "Epoch 25\t Accuracy of the network on the 10000 test images: 60 %\n",
      "[27,   200] loss: 0.031\n",
      "[27,   400] loss: 0.032\n",
      "[27,   600] loss: 0.034\n",
      "[27,   800] loss: 0.035\n",
      "[27,  1000] loss: 0.035\n",
      "[27,  1200] loss: 0.038\n",
      "[27,  1400] loss: 0.038\n",
      "Epoch 26\t Accuracy of the network on the 10000 test images: 59 %\n",
      "[28,   200] loss: 0.028\n",
      "[28,   400] loss: 0.031\n",
      "[28,   600] loss: 0.032\n",
      "[28,   800] loss: 0.033\n",
      "[28,  1000] loss: 0.032\n",
      "[28,  1200] loss: 0.033\n",
      "[28,  1400] loss: 0.033\n",
      "Epoch 27\t Accuracy of the network on the 10000 test images: 60 %\n",
      "[29,   200] loss: 0.026\n",
      "[29,   400] loss: 0.028\n",
      "[29,   600] loss: 0.027\n",
      "[29,   800] loss: 0.027\n",
      "[29,  1000] loss: 0.031\n",
      "[29,  1200] loss: 0.030\n",
      "[29,  1400] loss: 0.031\n",
      "Epoch 28\t Accuracy of the network on the 10000 test images: 60 %\n",
      "[30,   200] loss: 0.023\n",
      "[30,   400] loss: 0.024\n",
      "[30,   600] loss: 0.025\n",
      "[30,   800] loss: 0.027\n",
      "[30,  1000] loss: 0.028\n",
      "[30,  1200] loss: 0.027\n",
      "[30,  1400] loss: 0.028\n",
      "Epoch 29\t Accuracy of the network on the 10000 test images: 60 %\n",
      "[31,   200] loss: 0.021\n",
      "[31,   400] loss: 0.023\n",
      "[31,   600] loss: 0.023\n",
      "[31,   800] loss: 0.025\n",
      "[31,  1000] loss: 0.026\n",
      "[31,  1200] loss: 0.027\n",
      "[31,  1400] loss: 0.028\n",
      "Epoch 30\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[32,   200] loss: 0.021\n",
      "[32,   400] loss: 0.021\n",
      "[32,   600] loss: 0.022\n",
      "[32,   800] loss: 0.022\n",
      "[32,  1000] loss: 0.022\n",
      "[32,  1200] loss: 0.022\n",
      "[32,  1400] loss: 0.023\n",
      "Epoch 31\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[33,   200] loss: 0.018\n",
      "[33,   400] loss: 0.020\n",
      "[33,   600] loss: 0.019\n",
      "[33,   800] loss: 0.020\n",
      "[33,  1000] loss: 0.021\n",
      "[33,  1200] loss: 0.023\n",
      "[33,  1400] loss: 0.022\n",
      "Epoch 32\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[34,   200] loss: 0.017\n",
      "[34,   400] loss: 0.017\n",
      "[34,   600] loss: 0.018\n",
      "[34,   800] loss: 0.019\n",
      "[34,  1000] loss: 0.021\n",
      "[34,  1200] loss: 0.020\n",
      "[34,  1400] loss: 0.020\n",
      "Epoch 33\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[35,   200] loss: 0.016\n",
      "[35,   400] loss: 0.016\n",
      "[35,   600] loss: 0.017\n",
      "[35,   800] loss: 0.016\n",
      "[35,  1000] loss: 0.018\n",
      "[35,  1200] loss: 0.019\n",
      "[35,  1400] loss: 0.022\n",
      "Epoch 34\t Accuracy of the network on the 10000 test images: 60 %\n",
      "[36,   200] loss: 0.015\n",
      "[36,   400] loss: 0.014\n",
      "[36,   600] loss: 0.017\n",
      "[36,   800] loss: 0.017\n",
      "[36,  1000] loss: 0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36,  1200] loss: 0.016\n",
      "[36,  1400] loss: 0.016\n",
      "Epoch 35\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[37,   200] loss: 0.013\n",
      "[37,   400] loss: 0.012\n",
      "[37,   600] loss: 0.014\n",
      "[37,   800] loss: 0.016\n",
      "[37,  1000] loss: 0.016\n",
      "[37,  1200] loss: 0.016\n",
      "[37,  1400] loss: 0.014\n",
      "Epoch 36\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[38,   200] loss: 0.013\n",
      "[38,   400] loss: 0.013\n",
      "[38,   600] loss: 0.014\n",
      "[38,   800] loss: 0.014\n",
      "[38,  1000] loss: 0.014\n",
      "[38,  1200] loss: 0.013\n",
      "[38,  1400] loss: 0.016\n",
      "Epoch 37\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[39,   200] loss: 0.011\n",
      "[39,   400] loss: 0.012\n",
      "[39,   600] loss: 0.014\n",
      "[39,   800] loss: 0.012\n",
      "[39,  1000] loss: 0.013\n",
      "[39,  1200] loss: 0.014\n",
      "[39,  1400] loss: 0.016\n",
      "Epoch 38\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[40,   200] loss: 0.010\n",
      "[40,   400] loss: 0.011\n",
      "[40,   600] loss: 0.010\n",
      "[40,   800] loss: 0.012\n",
      "[40,  1000] loss: 0.012\n",
      "[40,  1200] loss: 0.012\n",
      "[40,  1400] loss: 0.012\n",
      "Epoch 39\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[41,   200] loss: 0.010\n",
      "[41,   400] loss: 0.011\n",
      "[41,   600] loss: 0.012\n",
      "[41,   800] loss: 0.011\n",
      "[41,  1000] loss: 0.010\n",
      "[41,  1200] loss: 0.011\n",
      "[41,  1400] loss: 0.014\n",
      "Epoch 40\t Accuracy of the network on the 10000 test images: 62 %\n",
      "[42,   200] loss: 0.010\n",
      "[42,   400] loss: 0.010\n",
      "[42,   600] loss: 0.012\n",
      "[42,   800] loss: 0.010\n",
      "[42,  1000] loss: 0.012\n",
      "[42,  1200] loss: 0.011\n",
      "[42,  1400] loss: 0.012\n",
      "Epoch 41\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[43,   200] loss: 0.009\n",
      "[43,   400] loss: 0.010\n",
      "[43,   600] loss: 0.010\n",
      "[43,   800] loss: 0.011\n",
      "[43,  1000] loss: 0.010\n",
      "[43,  1200] loss: 0.010\n",
      "[43,  1400] loss: 0.011\n",
      "Epoch 42\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[44,   200] loss: 0.009\n",
      "[44,   400] loss: 0.008\n",
      "[44,   600] loss: 0.009\n",
      "[44,   800] loss: 0.009\n",
      "[44,  1000] loss: 0.011\n",
      "[44,  1200] loss: 0.010\n",
      "[44,  1400] loss: 0.011\n",
      "Epoch 43\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[45,   200] loss: 0.009\n",
      "[45,   400] loss: 0.009\n",
      "[45,   600] loss: 0.009\n",
      "[45,   800] loss: 0.010\n",
      "[45,  1000] loss: 0.009\n",
      "[45,  1200] loss: 0.008\n",
      "[45,  1400] loss: 0.009\n",
      "Epoch 44\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[46,   200] loss: 0.009\n",
      "[46,   400] loss: 0.008\n",
      "[46,   600] loss: 0.008\n",
      "[46,   800] loss: 0.007\n",
      "[46,  1000] loss: 0.009\n",
      "[46,  1200] loss: 0.009\n",
      "[46,  1400] loss: 0.009\n",
      "Epoch 45\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[47,   200] loss: 0.007\n",
      "[47,   400] loss: 0.007\n",
      "[47,   600] loss: 0.008\n",
      "[47,   800] loss: 0.008\n",
      "[47,  1000] loss: 0.008\n",
      "[47,  1200] loss: 0.008\n",
      "[47,  1400] loss: 0.008\n",
      "Epoch 46\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[48,   200] loss: 0.007\n",
      "[48,   400] loss: 0.007\n",
      "[48,   600] loss: 0.008\n",
      "[48,   800] loss: 0.009\n",
      "[48,  1000] loss: 0.009\n",
      "[48,  1200] loss: 0.008\n",
      "[48,  1400] loss: 0.009\n",
      "Epoch 47\t Accuracy of the network on the 10000 test images: 61 %\n",
      "[49,   200] loss: 0.007\n",
      "[49,   400] loss: 0.007\n",
      "[49,   600] loss: 0.008\n",
      "[49,   800] loss: 0.007\n",
      "[49,  1000] loss: 0.008\n",
      "[49,  1200] loss: 0.008\n",
      "[49,  1400] loss: 0.008\n",
      "Epoch 48\t Accuracy of the network on the 10000 test images: 62 %\n",
      "[50,   200] loss: 0.005\n",
      "[50,   400] loss: 0.007\n",
      "[50,   600] loss: 0.006\n",
      "[50,   800] loss: 0.006\n",
      "[50,  1000] loss: 0.006\n",
      "[50,  1200] loss: 0.007\n",
      "[50,  1400] loss: 0.008\n",
      "Epoch 49\t Accuracy of the network on the 10000 test images: 62 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_acc.append(100 * correct / total)\n",
    "    print(f'Epoch {epoch}\\t Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0167b5a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T17:08:55.879911Z",
     "start_time": "2021-07-27T17:08:55.073387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class airplane is: 77.8 %\n",
      "Accuracy for class automobile is: 85.2 %\n",
      "Accuracy for class bird  is: 69.8 %\n",
      "Accuracy for class cat   is: 52.1 %\n",
      "Accuracy for class deer  is: 74.8 %\n",
      "Accuracy for class dog   is: 67.5 %\n",
      "Accuracy for class frog  is: 80.2 %\n",
      "Accuracy for class horse is: 75.0 %\n",
      "Accuracy for class ship  is: 83.2 %\n",
      "Accuracy for class truck is: 81.2 %\n"
     ]
    }
   ],
   "source": [
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2504854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T17:08:51.777792Z",
     "start_time": "2021-07-27T17:08:50.972639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 74 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63ebfa2",
   "metadata": {},
   "source": [
    "## ViT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b63edd",
   "metadata": {},
   "source": [
    "### PyTorch transformer layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a4ef0fef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T19:39:19.738505Z",
     "start_time": "2021-07-27T19:39:19.709785Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(512, 8, activation='gelu')\n",
    "net = nn.Sequential(\n",
    "    PatchEmbed(img_size=32, patch_size=8, embed_dim=512),\n",
    "    nn.TransformerEncoder(encoder_layer, 6),\n",
    "    nn.Linear(512, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "41773f84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T19:39:23.826195Z",
     "start_time": "2021-07-27T19:39:23.362057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.1617e-01,  3.9982e-01,  1.2600e-01,  ..., -4.5802e-01,\n",
       "          -3.3091e-01,  6.8654e-01],\n",
       "         [ 2.4491e-01, -5.5424e-02, -8.8039e-02,  ..., -6.2316e-01,\n",
       "          -3.2469e-01,  7.0556e-01],\n",
       "         [ 3.4414e-01, -3.4280e-01,  1.1338e-01,  ..., -9.5840e-01,\n",
       "           2.0983e-01,  1.1120e+00],\n",
       "         ...,\n",
       "         [-4.4272e-01,  9.8886e-01,  6.4270e-02,  ...,  6.8520e-01,\n",
       "          -5.5693e-01, -3.9169e-01],\n",
       "         [-6.6131e-02,  6.8598e-01,  5.7281e-01,  ...,  3.9021e-01,\n",
       "          -7.4485e-01, -2.3743e-01],\n",
       "         [-9.9447e-02,  7.5286e-01,  4.1983e-01,  ...,  4.8694e-01,\n",
       "          -6.7457e-01, -5.4904e-01]],\n",
       "\n",
       "        [[ 3.4716e-01,  4.9240e-01,  3.8271e-01,  ..., -1.5311e-01,\n",
       "           2.8414e-01,  4.1890e-01],\n",
       "         [ 4.8921e-01, -1.5585e-01,  2.9613e-01,  ..., -8.2275e-01,\n",
       "          -3.1350e-01,  7.6295e-02],\n",
       "         [ 6.8373e-01, -4.2024e-01, -2.2619e-01,  ..., -1.1394e-01,\n",
       "          -5.7316e-01,  4.3660e-01],\n",
       "         ...,\n",
       "         [-4.8353e-01,  1.0870e+00,  4.3121e-01,  ...,  7.1565e-01,\n",
       "           1.9682e-01, -4.7062e-01],\n",
       "         [ 3.0092e-02,  6.6939e-01,  5.2326e-01,  ...,  2.4807e-01,\n",
       "          -4.3231e-01, -2.6042e-01],\n",
       "         [ 8.2682e-02,  6.3291e-01,  1.9893e-01,  ...,  6.0327e-01,\n",
       "          -6.1526e-01, -4.5637e-01]],\n",
       "\n",
       "        [[ 4.5137e-01,  4.5498e-01,  1.3970e-01,  ..., -2.5671e-01,\n",
       "          -2.3083e-02,  7.9021e-01],\n",
       "         [ 4.5156e-01, -1.5139e-01, -7.8524e-02,  ..., -6.2049e-01,\n",
       "          -5.7961e-01,  1.1443e+00],\n",
       "         [ 3.0859e-01, -6.4291e-01,  1.9659e-01,  ..., -7.0373e-01,\n",
       "          -3.2068e-01,  1.2064e+00],\n",
       "         ...,\n",
       "         [-1.2663e-01,  9.5092e-01,  5.4071e-01,  ...,  1.0454e+00,\n",
       "          -1.9518e-01, -1.5128e-01],\n",
       "         [ 1.4979e-01,  7.1699e-01,  1.2490e+00,  ...,  6.4552e-01,\n",
       "          -3.1108e-01,  1.2918e-01],\n",
       "         [-7.0288e-02,  8.8995e-01,  5.5699e-01,  ...,  9.8238e-01,\n",
       "          -8.0407e-01,  5.4752e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 5.9819e-01,  4.7810e-01, -3.0775e-02,  ...,  2.6976e-01,\n",
       "           3.9498e-02,  3.4903e-01],\n",
       "         [ 3.9377e-01,  2.5164e-01,  4.2509e-01,  ...,  1.1987e-01,\n",
       "           3.7793e-02,  6.6967e-01],\n",
       "         [-3.2368e-01, -2.8950e-01, -1.9524e-01,  ..., -8.7527e-01,\n",
       "           4.8640e-01,  4.7281e-02],\n",
       "         ...,\n",
       "         [-4.0395e-01,  9.1457e-01,  3.7605e-01,  ...,  6.4804e-01,\n",
       "          -6.9156e-01, -3.9175e-01],\n",
       "         [-3.2988e-01,  5.9155e-01,  3.8604e-01,  ...,  6.9452e-01,\n",
       "          -2.3131e-02, -9.6343e-02],\n",
       "         [ 8.3066e-02,  4.2633e-01,  9.6854e-01,  ...,  9.7341e-01,\n",
       "          -7.0434e-02, -3.4105e-01]],\n",
       "\n",
       "        [[-8.9713e-02,  3.2320e-01,  1.7978e-02,  ..., -7.2573e-01,\n",
       "          -5.7747e-02, -8.6960e-02],\n",
       "         [ 1.3038e-01,  2.6469e-01, -1.2178e-01,  ..., -4.7636e-01,\n",
       "          -9.0076e-02,  5.3141e-01],\n",
       "         [-1.8411e-01, -5.0460e-01, -1.6220e-01,  ..., -9.8577e-01,\n",
       "           4.2136e-01,  5.3478e-01],\n",
       "         ...,\n",
       "         [-3.8500e-01,  8.5759e-01, -1.4821e-02,  ...,  8.0077e-01,\n",
       "          -3.9291e-01, -7.1381e-01],\n",
       "         [-3.0729e-01,  1.1249e+00,  2.0448e-01,  ...,  8.6106e-01,\n",
       "          -1.9676e-01, -2.0154e-01],\n",
       "         [-4.6718e-01,  6.9698e-01, -6.0710e-03,  ...,  2.9168e-01,\n",
       "          -5.0843e-01,  6.2275e-04]],\n",
       "\n",
       "        [[ 1.5900e-01,  2.1504e-01,  3.6685e-01,  ...,  9.8388e-02,\n",
       "           2.7628e-01,  4.1691e-01],\n",
       "         [ 3.5635e-02,  2.5889e-01,  4.0464e-01,  ...,  3.8103e-01,\n",
       "           3.6595e-01,  9.1310e-01],\n",
       "         [ 3.4087e-01, -1.9889e-01,  2.5754e-01,  ..., -1.9139e-01,\n",
       "           3.2443e-01,  9.4569e-01],\n",
       "         ...,\n",
       "         [-5.0339e-01,  1.2647e+00,  3.1529e-01,  ...,  6.8131e-01,\n",
       "          -4.5380e-01, -6.4168e-01],\n",
       "         [-4.3352e-02,  1.2702e+00,  5.0184e-01,  ...,  6.4448e-01,\n",
       "          -5.0145e-01, -2.2690e-01],\n",
       "         [-5.6957e-01,  6.9854e-01,  1.2957e-01,  ...,  1.0560e+00,\n",
       "          -2.0019e-01, -7.0473e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c0911122",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T19:39:13.338974Z",
     "start_time": "2021-07-27T19:39:13.326186Z"
    }
   },
   "outputs": [],
   "source": [
    "def drop_path(x, drop_prob: float = 0., training: bool = False):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
    "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
    "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
    "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
    "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
    "    'survival rate' as the argument.\n",
    "    \"\"\"\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = 1 - drop_prob\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
    "    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
    "    random_tensor.floor_()  # binarize\n",
    "    output = x.div(keep_prob) * random_tensor\n",
    "    return output\n",
    "\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training)\n",
    "    \n",
    "    \n",
    "class Mlp(nn.Module):\n",
    "    \"\"\" MLP as used in Vision Transformer, MLP-Mixer and related networks\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def to_2tuple(size):\n",
    "    return (size, size)\n",
    "    \n",
    "    \n",
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\" 2D Image to Patch Embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768, norm_layer=None, flatten=True):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.grid_size = (img_size[0] // patch_size[0], img_size[1] // patch_size[1])\n",
    "        self.num_patches = self.grid_size[0] * self.grid_size[1]\n",
    "        self.flatten = flatten\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        x = self.proj(x)\n",
    "        if self.flatten:\n",
    "            x = rearrange(x, \"b c h w -> b (h w) c\")\n",
    "        x = self.norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b066702d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-27T19:35:39.412491Z",
     "start_time": "2021-07-27T19:35:39.406029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "patch_embed = PatchEmbed(img_size=32, patch_size=8, embed_dim=512)\n",
    "patches = patch_embed(images[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffef8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop)\n",
    "        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75942d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionTransformer(nn.Module):\n",
    "    \"\"\" Vision Transformer\n",
    "    A PyTorch impl of : `An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale`\n",
    "        - https://arxiv.org/abs/2010.11929\n",
    "    Includes distillation token & head support for `DeiT: Data-efficient Image Transformers`\n",
    "        - https://arxiv.org/abs/2012.12877\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dim=768, depth=12,\n",
    "                 num_heads=12, mlp_ratio=4., qkv_bias=True, representation_size=None, distilled=False,\n",
    "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0., embed_layer=PatchEmbed, norm_layer=None,\n",
    "                 act_layer=None, weight_init=''):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_size (int, tuple): input image size\n",
    "            patch_size (int, tuple): patch size\n",
    "            in_chans (int): number of input channels\n",
    "            num_classes (int): number of classes for classification head\n",
    "            embed_dim (int): embedding dimension\n",
    "            depth (int): depth of transformer\n",
    "            num_heads (int): number of attention heads\n",
    "            mlp_ratio (int): ratio of mlp hidden dim to embedding dim\n",
    "            qkv_bias (bool): enable bias for qkv if True\n",
    "            representation_size (Optional[int]): enable and set representation layer (pre-logits) to this value if set\n",
    "            distilled (bool): model includes a distillation token and head as in DeiT models\n",
    "            drop_rate (float): dropout rate\n",
    "            attn_drop_rate (float): attention dropout rate\n",
    "            drop_path_rate (float): stochastic depth rate\n",
    "            embed_layer (nn.Module): patch embedding layer\n",
    "            norm_layer: (nn.Module): normalization layer\n",
    "            weight_init: (str): weight init scheme\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
    "        self.num_tokens = 2 if distilled else 1\n",
    "        norm_layer = norm_layer or partial(nn.LayerNorm, eps=1e-6)\n",
    "        act_layer = act_layer or nn.GELU\n",
    "\n",
    "        self.patch_embed = embed_layer(\n",
    "            img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.dist_token = nn.Parameter(torch.zeros(1, 1, embed_dim)) if distilled else None\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + self.num_tokens, embed_dim))\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            Block(\n",
    "                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer, act_layer=act_layer)\n",
    "            for i in range(depth)])\n",
    "        self.norm = norm_layer(embed_dim)\n",
    "\n",
    "        # Representation layer\n",
    "        if representation_size and not distilled:\n",
    "            self.num_features = representation_size\n",
    "            self.pre_logits = nn.Sequential(OrderedDict([\n",
    "                ('fc', nn.Linear(embed_dim, representation_size)),\n",
    "                ('act', nn.Tanh())\n",
    "            ]))\n",
    "        else:\n",
    "            self.pre_logits = nn.Identity()\n",
    "\n",
    "        # Classifier head(s)\n",
    "        self.head = nn.Linear(self.num_features, num_classes) if num_classes > 0 else nn.Identity()\n",
    "        self.head_dist = None\n",
    "        if distilled:\n",
    "            self.head_dist = nn.Linear(self.embed_dim, self.num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "        self.init_weights(weight_init)\n",
    "\n",
    "    def init_weights(self, mode=''):\n",
    "        assert mode in ('jax', 'jax_nlhb', 'nlhb', '')\n",
    "        head_bias = -math.log(self.num_classes) if 'nlhb' in mode else 0.\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "        if self.dist_token is not None:\n",
    "            trunc_normal_(self.dist_token, std=.02)\n",
    "        if mode.startswith('jax'):\n",
    "            # leave cls token as zeros to match jax impl\n",
    "            named_apply(partial(_init_vit_weights, head_bias=head_bias, jax_impl=True), self)\n",
    "        else:\n",
    "            trunc_normal_(self.cls_token, std=.02)\n",
    "            self.apply(_init_vit_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        # this fn left here for compat with downstream users\n",
    "        _init_vit_weights(m)\n",
    "\n",
    "    @torch.jit.ignore()\n",
    "    def load_pretrained(self, checkpoint_path, prefix=''):\n",
    "        _load_weights(self, checkpoint_path, prefix)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'pos_embed', 'cls_token', 'dist_token'}\n",
    "\n",
    "    def get_classifier(self):\n",
    "        if self.dist_token is None:\n",
    "            return self.head\n",
    "        else:\n",
    "            return self.head, self.head_dist\n",
    "\n",
    "    def reset_classifier(self, num_classes, global_pool=''):\n",
    "        self.num_classes = num_classes\n",
    "        self.head = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "        if self.num_tokens == 2:\n",
    "            self.head_dist = nn.Linear(self.embed_dim, self.num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        cls_token = self.cls_token.expand(x.shape[0], -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "        if self.dist_token is None:\n",
    "            x = torch.cat((cls_token, x), dim=1)\n",
    "        else:\n",
    "            x = torch.cat((cls_token, self.dist_token.expand(x.shape[0], -1, -1), x), dim=1)\n",
    "        x = self.pos_drop(x + self.pos_embed)\n",
    "        x = self.blocks(x)\n",
    "        x = self.norm(x)\n",
    "        if self.dist_token is None:\n",
    "            return self.pre_logits(x[:, 0])\n",
    "        else:\n",
    "            return x[:, 0], x[:, 1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        if self.head_dist is not None:\n",
    "            x, x_dist = self.head(x[0]), self.head_dist(x[1])  # x must be a tuple\n",
    "            if self.training and not torch.jit.is_scripting():\n",
    "                # during inference, return the average of both classifier predictions\n",
    "                return x, x_dist\n",
    "            else:\n",
    "                return (x + x_dist) / 2\n",
    "        else:\n",
    "            x = self.head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def _init_vit_weights(module: nn.Module, name: str = '', head_bias: float = 0., jax_impl: bool = False):\n",
    "    \"\"\" ViT weight initialization\n",
    "    * When called without n, head_bias, jax_impl args it will behave exactly the same\n",
    "      as my original init for compatibility with prev hparam / downstream use cases (ie DeiT).\n",
    "    * When called w/ valid n (module name) and jax_impl=True, will (hopefully) match JAX impl\n",
    "    \"\"\"\n",
    "    if isinstance(module, nn.Linear):\n",
    "        if name.startswith('head'):\n",
    "            nn.init.zeros_(module.weight)\n",
    "            nn.init.constant_(module.bias, head_bias)\n",
    "        elif name.startswith('pre_logits'):\n",
    "            lecun_normal_(module.weight)\n",
    "            nn.init.zeros_(module.bias)\n",
    "        else:\n",
    "            if jax_impl:\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    if 'mlp' in name:\n",
    "                        nn.init.normal_(module.bias, std=1e-6)\n",
    "                    else:\n",
    "                        nn.init.zeros_(module.bias)\n",
    "            else:\n",
    "                trunc_normal_(module.weight, std=.02)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "    elif jax_impl and isinstance(module, nn.Conv2d):\n",
    "        # NOTE conv was left to pytorch default in my original init\n",
    "        lecun_normal_(module.weight)\n",
    "        if module.bias is not None:\n",
    "            nn.init.zeros_(module.bias)\n",
    "    elif isinstance(module, (nn.LayerNorm, nn.GroupNorm, nn.BatchNorm2d)):\n",
    "        nn.init.zeros_(module.bias)\n",
    "        nn.init.ones_(module.weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
